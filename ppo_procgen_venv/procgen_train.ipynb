{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from procgen import ProcgenEnv\n",
    "\n",
    "from utils.envs import make_ProcgenEnvs\n",
    "\n",
    "from agent.discrete_ppo import PPO\n",
    "from agent.models import ImpalaModel, CNNBase"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "torch.set_num_threads(1)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "id": "e63b9c685613f286",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('making envs...')\n",
    "start_level = 0\n",
    "num_levels = 200\n",
    "num_test_levels = 200\n",
    "num_envs=32\n",
    "\n",
    "train_envs = make_ProcgenEnvs(num_envs=num_envs,\n",
    "                              env_name='coinrun',\n",
    "                              start_level=start_level,\n",
    "                              num_levels=num_levels,\n",
    "                              distribution_mode='easy',\n",
    "                              use_generated_assets=False,\n",
    "                              use_backgrounds=True,\n",
    "                              restrict_themes=False,\n",
    "                              use_monochrome_assets=False,\n",
    "                              rand_seed=0,\n",
    "                              device=device)\n",
    "\n",
    "test_envs = make_ProcgenEnvs(num_envs=1,\n",
    "                             env_name='coinrun',\n",
    "                             start_level=start_level + num_levels,\n",
    "                             num_levels=num_test_levels,\n",
    "                             distribution_mode='easy',\n",
    "                             use_generated_assets=False,\n",
    "                             use_backgrounds=True,\n",
    "                             restrict_themes=False,\n",
    "                             use_monochrome_assets=False,\n",
    "                             rand_seed=0,\n",
    "                             device=device)"
   ],
   "id": "7741c4d087eacab9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# obs = train_envs.reset()\n",
    "# print(train_envs.observation_space.shape)"
   ],
   "id": "ed66ea1ea3dd6017",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def evaluate_agent(env, agent, num_levels=200):\n",
    "    sum_reward = 0\n",
    "    max_ep_len = 1000\n",
    "    for _ in range(num_levels):\n",
    "        state = env.reset()\n",
    "\n",
    "        for t in range(1, max_ep_len + 1):\n",
    "            action, _, _ = agent.select_action(state)\n",
    "            state, reward, done, _ = env.step(action.detach().cpu().numpy())\n",
    "\n",
    "            sum_reward += reward\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "    return sum_reward / num_levels"
   ],
   "id": "c9f6e3e81acea721",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ppo_agent = PPO(state_dim=(num_envs, 3, 64, 64), action_dim=15, actor_critic_model=ImpalaModel, lr=5e-4, gamma=0.99, K_epochs=3,\n",
    "                eps_clip=0.2, use_gae=True, gae_lambda=0.95, mini_batch_size=512 * num_envs // 8, use_clipped_value_loss=True, device=device)"
   ],
   "id": "4897d702796d3093",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_steps = 25_000_000\n",
    "update_timestep = 512\n",
    "summary_freq = 10_000\n",
    "\n",
    "time_step = 0\n",
    "running_reward = 0\n",
    "running_episodes = num_envs\n",
    "\n",
    "state = train_envs.reset()\n",
    "while time_step * num_envs < num_steps:\n",
    "\n",
    "    # select action with policy\n",
    "    with torch.no_grad():\n",
    "        action, action_logprob, state_val = ppo_agent.select_action(state)\n",
    "    next_state, reward, done, info = train_envs.step(action.detach().cpu().numpy())\n",
    "\n",
    "    # saving reward and is_terminals\n",
    "    ppo_agent.buffer.insert(state, action, action_logprob, reward, next_state, state_val, done)\n",
    "\n",
    "    state = next_state\n",
    "    time_step += 1\n",
    "    running_reward += reward.sum()\n",
    "    running_episodes += done.sum()\n",
    "\n",
    "    # update PPO agent\n",
    "    if time_step % update_timestep == 0:\n",
    "        ppo_agent.update()\n",
    "\n",
    "    if time_step % summary_freq == 0:\n",
    "        test_ave_reward = evaluate_agent(test_envs, ppo_agent, num_levels=num_test_levels)\n",
    "        print(f\"Timestep: {time_step * num_envs}, \\t\\tAverage Train Reward: {running_reward / running_episodes: .2f}, \\t\\tAverage Test Reward: {test_ave_reward.item(): .2f}\")\n",
    "\n",
    "        running_reward = 0\n",
    "        running_episodes = 0\n",
    "\n",
    "    # save model weights\n",
    "    # if time_step % save_model_freq == 0:\n",
    "    #     print(\"--------------------------------------------------------------------------------------------\")\n",
    "    #     print(\"saving model at : \" + checkpoint_path)\n",
    "    #     ppo_agent.save(checkpoint_path)\n",
    "    #     print(\"model saved\")\n",
    "    #     print(\"Elapsed Time  : \", datetime.now().replace(microsecond=0) - start_time)\n",
    "    #     print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "train_envs.close()"
   ],
   "id": "a366b47f9032ca17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5dccb6624af8814e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
